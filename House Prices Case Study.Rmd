---
title: "Case Study: House Prices and Regressions"
subtitle: "DS 6371 Project 1"
author: "Nicholas Sager"
date: "3/31/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)

# Required Libraries
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggthemes)
library(caret)
#library(e1071)
#library(class)
```


## Introduction

Introduction text

For an interactive app to visualize this data, please see: [Shiny App](https://nicksager.shinyapps.io/CaseStudy1/)

## Data Description

A description of the data, where it came from, and what it contains.

### Read the Data

First, we will read in the beers data, and merge the breweries data so that each beer has brewery data associated with it. Then we will view a few row to make sure it looks ok. 
```{r}
train <- read.csv("Data/train.csv")
test <- read.csv("Data/test.csv")

# Merge the data frames and add a column indicating whether they come from the train or test set
train$train <- 1
test$SalePrice <- NA
test$train <- 0
ames <- rbind(train, test)

# Verify data frame
head(ames)
str(ames)
summary(ames)
```
For data cleaning purposes, we will merge test and train into one dataset, keeping in mind that the 1459 NA's in the SalePrice column are from the test set. We will also add a column to indicate whether the row is from the train or test set.

### Data Exploration
Next, we will start exploring the data for insights into the Ames housing market as well as what variables we need to change, clean, or create.

First, we will visualize where the NA values are and whether it will affect the first to parameters we are concerned about: Sale Price and Gross Living Area.
```{r}
# Summarize NA's by  column
ames %>%
  summarise_all(funs(sum(is.na(.)))) %>%
  gather(key = "Column", value = "NA_Count", -1) %>%
  filter(NA_Count > 0) %>%
  ggplot(aes(x = reorder(Column, NA_Count), y = NA_Count)) +
  geom_col() +
  coord_flip() +
  theme_gdocs() +
  labs(title = "Number of NA's by Column", x = "Column", y = "NA Count")

# Create a table of the missing NAs by column
ames %>%
  summarise_all(funs(sum(is.na(.)))) %>%
  gather(key = "Column", value = "NA_Count", -1) %>%
  filter(NA_Count > 0) %>%
  arrange(desc(NA_Count)) %>%
  kable()
```
There are not too many NA's in the data set, and they appear mostly to do with lack of a certain feature. For example, if a house does not have a pool, then the PoolQC column will be NA. We will need to decide how to handle these NA's, but for now we will leave them as is and continue with the analysis of Sale Price and Gross Living Area.

## Analysis 1: Sale Price and Gross Living Area

Restate the problem here

### Build and fit the model

#### Entire Dataset
```{r}
# Plot Sale Price vs. Gross Living Area colored by neighborhood, omitting rows where SalePrice is NA
ames %>%
  filter(!is.na(SalePrice)) %>%
  ggplot(aes(x = GrLivArea, y = SalePrice, color = Neighborhood)) +
  geom_point() +
  theme_gdocs() +
  labs(title = "Sale Price vs. Gross Living Area by Neighborhood", x = "Gross Living Area", y = "Sale Price")
```
There is clearly a relationship between Sale Price and Gross Living Area, and the neighborhoods appear to have a similar relationship. We will now look at log transformations of the data to see if there is more linear relationship.
```{r}
# Plot log(Sale Price) vs. log(Gross Living Area) colored by neighborhood, omitting rows where SalePrice is NA
ames %>%
  filter(!is.na(SalePrice)) %>%
  ggplot(aes(x = log(GrLivArea), y = log(SalePrice), color = Neighborhood)) +
  geom_point() +
  theme_gdocs() +
  labs(
    title = "log(Sale Price) vs. log(Gross Living Area) by Neighborhood",
    x = "log(Gross Living Area)",
    y = "log(Sale Price)"
  )
```
This relationship appears to be more linear. We will create columns for the log of Sale Price and Gross Living Area and use these in our analysis.
```{r}
# Create columns for log(SalePrice) and log(GrLivArea)
ames$logSalePrice <- log(ames$SalePrice)
ames$logGrLivArea <- log(ames$GrLivArea)
```

#### Century 21 Area

Next, we will visualize the relationship between log Sale Price and log Gross Living Area for the neighborhoods that Century21 operates in: NAmes, Edwards and BrkSide.
```{r}
# Plot log(Sale Price) vs. log(Gross Living Area) colored by neighborhood, omitting rows where SalePrice is NA for only the neighborhoods of interest
century21 <-
  ames %>%
  filter(!is.na(SalePrice)) %>%
  filter(Neighborhood %in% c("NAmes", "Edwards", "BrkSide")) 
century21 %>%
  ggplot(aes(x = logGrLivArea, y = logSalePrice, color = Neighborhood)) +
  geom_point() +
  theme_gdocs() +
  labs(
    title = "log(Sale Price) vs. log(Gross Living Area) by Neighborhood",
    x = "log(Gross Living Area)",
    y = "log(Sale Price)"
  )
```

The relationship appears to be linear, so we will fit a linear model using this data and asses whether it describes the Sale Prices accurately.
```{r}
# Fit a linear model to the data
fit1 <- lm(logSalePrice ~ logGrLivArea * Neighborhood, data = century21)
summary(fit1)

# Plot the data with the linear model superposed
century21 %>%
  ggplot(aes(x = logGrLivArea, y = logSalePrice, color = Neighborhood)) +
  geom_point() +
  theme_gdocs() +
  labs(
    title = "log(Sale Price) vs. log(Gross Living Area) by Neighborhood",
    x = "log(Gross Living Area)",
    y = "log(Sale Price)"
  ) +
  geom_smooth(
    method = "lm", formula = y ~ x, se = FALSE, size = 1,
    data = data.frame(
      logGrLivArea = century21$logGrLivArea,
      Neighborhood = century21$Neighborhood,
      logSalePrice = predict(fit1)
    )
  )

# Print parameter estimate table nicely. Not working, needs debugging
fit1 %>%
  summary() %>%
  {cbind(as.data.frame(coef(.)), .[["coefficients"]][, 2:4])} %>%
  setNames(c("Estimate", "Std. Error", "t-value", "Pr(>|t|)")) %>%
  rownames_to_column(var = "Term") %>%
  mutate(Term = ifelse(Term == "(Intercept)", "Intercept", Term)) %>%
  add_row(Term = "Adjusted R-squared", Estimate = round(.$adj.r.squared, 3), Std..Error = NA, `t-value` = NA, `Pr(>|t|)` = NA) %>%
  kable(digits = 3, align = "c") %>%
  kable_styling(full_width = FALSE)
```

### Check the Assumptions

#### Residual Plots
```{r}
# Plot the studentized residuals using base R
plot(fit1$fitted.values, fit1$residuals, type = "p") # Fitted values not correct, need logGrLivArea as in ggplot
plot(fit1$residuals)

# Decide which of these we like better ggplot or R

# Calculate studentized residuals
stud_res <- rstudent(fit1)
# Create a data frame with the studentized residuals
df <- data.frame(stud_res, logGrLivArea = model.frame(fit1)$logGrLivArea)

# Create a scatterplot of the studentized residuals
ggplot(df, aes(x = logGrLivArea, y = stud_res)) +
  geom_point() +
  labs(title = "Scatterplot of Studentized Residuals",
  x = "Studentized Residuals",
  y = "Frequency") +
  theme_minimal()

# Create histogram with normal curve
ggplot(df, aes(x = stud_res)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.5, fill = "lightblue", color = "black") +
  stat_function(fun = dnorm, args = list(mean = mean(df$stud_res), sd = sd(df$stud_res)), color = "blue", size = 1.2) +
  labs(title = "Histogram of Studentized Residuals with Normal Curve",
  x = "Studentized Residuals",
  y = "Frequency") +
  theme_minimal()
```

#### Influential Points
```{r}
# Plot the residuals vs. the fitted values
fit1 %>%
  plot()
```

### Comparing competing models

This is already done, just need to move it here. Adj R2, CV press

### Parameters (linear model)

Estimates, interpretation, confidence

### Conclusion

A short summary of the analysis

## RShiny App - Sale price and gross living area

Either embed the app here or link to it

## Analysis 2: Sale Price 

Restate the problem

### Data Cleaning
In order to use a linear regression model, we need to convert all of the categorical variables into dummy variables. We will also remove or impute the NA's in the data set. Please see the appendix for details on this process.
```{r}
# Data Cleaning
# Possible change setup so this isn't shown in the Output.

# Use the dummyVars() function to convert categorical variables into dummy variables
dummy_model <- dummyVars(~ ., data = ames)
ames_dummy <- as.data.frame(predict(dummy_model, newdata = ames))

# Handle NA values here

# Fill in all na values with the mean of the column
ames_dummy <- ames_dummy %>%
  mutate_all(~ ifelse(is.na(.), mean(., na.rm = TRUE), .)) %>%
  select(-one_of("MSZoningC (all)", "RoofMatlTar&Grv"))

# Summarize the amount of remaining NA's by column
colSums(is.na(ames_dummy))

# Split the data into training and testing sets
train <- ames_dummy[ames_dummy$train == 1, ]
test <- ames_dummy[ames_dummy$train == 0, ]
```

### Model Selection

talk about feature selection methods

#### Forward Selection
```{r}
# Forward Selection
# Use the stepAIC() function to perform forward selection
fit2 <- stepAIC(lm(logSalePrice ~ ., data = train), direction = "forward", trace = FALSE)
summary(fit2)

# Perform stepwise selection
set.seed(137)
ctrl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3,
)
fit2 <- train(logSalePrice ~ . - SalePrice,
  data = train,
  method = "glmStepAIC",
  trControl = ctrl,
  direction = "forward",
  penter = 0.05
)

summary(fit2)



# Get selected features
selected <- names(getVarImp(model, scale = FALSE)$importance)
selected

```

#### Backward Selection

#### Stepwise Selection

#### Custom features

### Model Evaluation

Adj R2, Internal CV press, Kaggle score

### Checking Assumptions

Residuals, Influential point (cooks d v leverage)

### Conclusion

Conclusion text

This analysis has answered the initial questions posed by Budweiser's request, and has perhaps raised even more. The authors hope that this analysis will be useful to Budweiser in their future product development. Any questions about this analysis or proposals for additional research can be directed to the authors at:

Nicholas Sager: nsager@smu.edu  
Steven Cox: sacox@mail.smu.edu

```{r output, include=FALSE, echo=FALSE}
# Write beers_breweries to a csv for later use in Shiny App
#write_csv(beers_breweries, "Data/beers_breweries.csv")
```


## Appendix 

Code.